{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97015a3b",
   "metadata": {},
   "source": [
    "### Simple Holdout validation\n",
    "\n",
    "- some fraction of data as test set.\n",
    "- training on the remaining data.\n",
    "- evaluation on test set\n",
    "- to avoid information leaks, also reserve a validation set.\n",
    "\n",
    "![image.png](./../public/image.png)\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "## for hyperparameters tuning \n",
    "\n",
    "num_validation_samples = 10000\n",
    "np.random.shuffle(data)\n",
    "validation_data = data[:num_validation_samples]\n",
    "training_data = data[num_validation_samples:]\n",
    "model = get_model()\n",
    "model.fit(training_data, ...)\n",
    "validation_score = model.evaluate(validation_data, ...)\n",
    "\n",
    "...\n",
    "\n",
    "## for final model with best parameters we have found\n",
    "\n",
    "model = get_model()\n",
    "model.fit(np.concatenate([training_data, \n",
    "validation_data]), ...)\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "\n",
    "```\n",
    "\n",
    "simplest evaluation protocol.\n",
    "\n",
    "### problems with it\n",
    "\n",
    "- little data means validation and test sets will contain too few samples to be statistically representative of the data at hand\n",
    "- if different random shuffling rounds of the data before splitting end up yielding very different measures of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80aa165",
   "metadata": {},
   "source": [
    "# K-fold validation\n",
    "\n",
    "- split data into K partitions of equal size.\n",
    "- for each partition i , train a model on the remaining K-1 partitions, and evaluate it on partition i.\n",
    "- final score is then the average of the K scores obtained.\n",
    "- this method helpful when the performance of our model shows significant variance based on train test split.\n",
    "\n",
    "![image.png](./../public/image2.png)\n",
    "\n",
    "\n",
    "### K-fold cross validation\n",
    "\n",
    "```python\n",
    "\n",
    "k=3\n",
    "num_validation_samples = len(data)//k\n",
    "np.random.shuffle(data)\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_smples * fold:\n",
    "    num_validation_samples * (fold+1)]\n",
    "    training_data = np.concatenate(data[:num_validation_samples * fold], data[num_validation_samples * (fold+1): ])\n",
    "    model = get_model()\n",
    "    model.fit(training_data, ...)\n",
    "    validation_score = model.evaluate(validation_data, ...)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "model = get_model()\n",
    "model.fit(data, ...)\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1d6b4",
   "metadata": {},
   "source": [
    "# Iterated K-Fold Validation with shuffling\n",
    "\n",
    "- for situations in which we have relatively little data available and we need to evaluate model as precisely as possible.\n",
    "\n",
    "- consists of applying K-fold validation multiple times, shuffling the data every time before splitting it K ways.\n",
    "\n",
    "- final score = average of the scores obtained at each run K-fold validation.\n",
    "\n",
    "- we end up training and evaluating P*K models (where P is the number of iterations we use), can be very expensive."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
