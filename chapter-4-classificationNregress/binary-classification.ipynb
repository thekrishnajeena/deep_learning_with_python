{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b370499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow.keras.datasets (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\krish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow.keras.datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow.keras.datasets\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# print(train_data, train_labels) \n",
    "word_index = imdb.get_word_index() #word_index is a dict mapping words to an integer index\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()]\n",
    ") #reversing dict so we can get word for number\n",
    "decoded_review = \" \".join(\n",
    "    [reverse_word_index.get(i-3, \"?\") for i in train_data[0]]\n",
    ") #decoded the review, indices are offset by 3, reserved for \"padding\", \"start of sequence\" and \"unknown\"\n",
    "\n",
    "print(decoded_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63e4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\n",
    "# encoding the integer sequences via multi-hot encoding\n",
    "\n",
    "# print(train_data)\n",
    "\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    # print(results)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "        \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# print(x_train)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe84c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n",
      "[1. 0. 0. ... 0. 1. 0.]\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(train_labels).astype(\"float32\") #vectorizing labels(turning them into NumPy arrays), casting them to float32 for compatibility and performance\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")\n",
    "\n",
    "print(train_labels)\n",
    "print(y_train)\n",
    "print(type( train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ca1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building your model\n",
    "\n",
    "# input data is vectors and the labels are scalars(1s and 0s), type of model that performs well on such a problem is plain stack of densely connected(Dense) layers with relu activation\n",
    "# for now choosing layers and units for each layer based on the book\n",
    "\n",
    "# model definition\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"), #first argument passed to each Dense layer is the number of units in the layer: the dimensionality of representation space of the layer\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# 16 units mean the weight matrix W will have shape (input_dimension, 16), dot product with W\n",
    "# will project the input data onto a 16-dimensional representation space, then add the bias vector b and apply relu operation\n",
    "# having more units(a higher dim representation space) allows our model to learn more complex represntations, but it makes the model more computatioinally expensive and may lead to learning \n",
    "# unwanted patterns(patterns that will improve performance on the training data but on the test data)\n",
    "\n",
    "# intermediate layers use relu as their activation function and the final layers uses a sigmoid activation\n",
    "# so as to output probability(a score between 0 and 1 indicating how likely the sample is to have the target 1: how likely review positive)\n",
    "\n",
    "# a relu(rectified linear unit) is a function meant to zero out negative values\n",
    "# where a sigmoid \"squashes\" arbitrary values into the [0,1] interval(something interpreted as probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f8ccf",
   "metadata": {},
   "source": [
    "<!-- Activation functions and why are they necessary -->\n",
    "\n",
    "without it(like relu), the dense layer would consist of two linear operations - a dot product and an addition:\n",
    "output = dot(input, W) + b\n",
    "\n",
    "the layer could only learn linear transformations(affine transformations) fo the input data: \n",
    "the hypothesis space of the layer would be the set of all possible linear transformations of the input data into a 16-dim space. Such a hypothesis space too restricted and won't benefit from multiple layers of representations as a deep stack of linear layers would still implement a linear operation.\n",
    "\n",
    "in order to get access to a much richer hypothesis space that benefits from deep representations, we need a non-linearity or activation function. relu a popular choice(other similar prelu, elu and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ca17349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we choose a loss function and an optimizer\n",
    "# it is best to use binary_crossentropy loss as best with models that output probabilities\n",
    "# Crossentropy is a quantity from the field of information theory that measures the distance between probability\n",
    "# distributions or in this case between the ground truth distribution and your predictions\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95619ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
